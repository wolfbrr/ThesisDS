{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install dependencies\n",
    "# !pip install pyarrow\n",
    "# !pip install  duckdb --upgrade --pre\n",
    "# !pip install wittgenstein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.model_selection import train_test_split,  GroupShuffleSplit\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import KBinsDiscretizer, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "## Duck Db imports\n",
    "import pyarrow.parquet as pq\n",
    "import duckdb\n",
    "\n",
    "# developed packages\n",
    "from utils import create_facts_and_examples, performance_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Import Data¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create duck db connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7fad63fda570>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = duckdb.connect(':memory:')\n",
    "# enable automatic query parallelization\n",
    "con.execute(\"PRAGMA threads=2\")\n",
    "# enable caching of parquet metadata\n",
    "con.execute(\"PRAGMA enable_object_cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading PAYSIM1 data and creating parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    con.sql('DROP TABLE df_fraud_tbl')\n",
    "    print(\"previous table dropped\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    con.sql(\"\"\"CREATE TABLE fraud_tbl AS SELECT * FROM 'fraud.parquet';\"\"\")\n",
    "except:\n",
    "    con.sql(\n",
    "    \"\"\"\n",
    "    copy 'DATA/paysim1/PS_20174392719_1491204439457_log.csv' to 'fraud.parquet';\n",
    "\"\"\")\n",
    "    con.sql(\"\"\"CREATE TABLE fraud_tbl AS SELECT * FROM 'fraud.parquet';\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating externarl origin and destination, Imputing zero values for external accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraud = con.sql(\"\"\" \n",
    "SELECT *,\n",
    "-- evaluating external accounts\n",
    "    oldbalanceOrg==0 and newbalanceOrig==0 as external_orig,\n",
    "    oldbalanceDest==0 and newbalanceDest==0 as external_dest,\n",
    "-- Imputing zero values for external accounts\n",
    "    CASE WHEN external_orig==True \n",
    "        THEN  amount\n",
    "        ELSE oldbalanceOrg\n",
    "    END AS oldbalanceOrg_imputed,\n",
    "    CASE WHEN external_dest==True \n",
    "        THEN  amount\n",
    "        ELSE newbalanceDest\n",
    "    END AS newbalanceDest_imputed, \n",
    "FROM fraud_tbl\n",
    "\"\"\").df()\n",
    "\n",
    "# testing\n",
    "slice_index = df_fraud['external_orig']==True\n",
    "\n",
    "assert np.sum(df_fraud[slice_index]['amount'] != df_fraud[slice_index]['oldbalanceOrg_imputed'] )==0, \"Wrong imputation for external origin\"\n",
    "\n",
    "slice_index = df_fraud['external_dest']==True\n",
    "\n",
    "assert np.sum(df_fraud[slice_index]['amount'] != df_fraud[slice_index]['newbalanceDest_imputed'] )==0, \"Wrong imputation for external destination\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data to train/test/val "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.15, random_state=42)\n",
    "for train_index, test_index in gss.split(df_fraud, groups=df_fraud['nameDest']):\n",
    "    df_train_total = df_fraud.loc[train_index]\n",
    "    df_test_       = df_fraud.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validation set is a part of train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_total = df_train_total.reset_index(drop=True)\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.15, random_state=42)\n",
    "for train_index, val_index in gss.split(df_train_total, groups=df_train_total['nameDest']):\n",
    "    df_train_ = df_train_total.loc[train_index]\n",
    "    df_val_   = df_train_total.loc[val_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### aggregation definition\n",
    "compute average, and maximum amount of transfer for the last 3, and 7 days for the destination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregates(df):\n",
    "    \"\"\" runs aggregations on pandas dataframe with help of duckdb\"\"\"\n",
    "    data = df.copy()\n",
    "    data = data.sort_values(by='step')\n",
    "    data=data.reset_index(drop=True).reset_index()\n",
    "    data = con.sql(\"\"\"\n",
    "        SELECT \n",
    "            *,\n",
    "\n",
    "-- calculate aggregetions (Average and Max) for last 7 including the current row for each name Destination\n",
    "            AVG(amount) OVER (PARTITION BY nameDest ORDER BY index ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS mean_last_7,\n",
    "            MAX(amount) OVER (PARTITION BY nameDest ORDER BY index ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS max_last_7,\n",
    "       \n",
    "-- calculate aggregetions (Average and Max) for last 3 including the current row for each name Destination\n",
    "            AVG(amount) OVER (PARTITION BY nameDest ORDER BY index ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) AS mean_last_3,\n",
    "            MAX(amount) OVER (PARTITION BY nameDest ORDER BY index ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) AS max_last_3,\n",
    "\n",
    "-- deviation from the aggregated values\n",
    "            amount-mean_last_7 as deviation_from_mean_7_days,\n",
    "            amount-mean_last_3 as deviation_from_mean_3_days,\n",
    "            amount-max_last_7 as deviation_from_max_7_days,\n",
    "            amount-max_last_3 as deviation_from_max_3_days,\n",
    "\n",
    "        FROM \n",
    "            data\n",
    "            ORDER BY index\n",
    "            \"\"\").df()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing class fit on train data and processes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    def __init__(self, scaler_columns):\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "        self.scaler_columns = scaler_columns\n",
    "        \n",
    "    def fit(self, train_data_frame):\n",
    "        \n",
    "        self.scaler.fit(train_data_frame[self.scaler_columns])\n",
    "        \n",
    "    def transform(self, data_frame):\n",
    "        \n",
    "        df = data_frame.copy()\n",
    "        \n",
    "        #scale numerical columns \n",
    "        df[self.scaler_columns] = self.scaler.transform(df[self.scaler_columns])\n",
    "        \n",
    "        ### run aggregation\n",
    "        df = aggregates(df)\n",
    "        \n",
    "        # one hot encoding and drop columns \n",
    "        df['distType'] = df[\"nameDest\"].str[0]\n",
    "        df = pd.get_dummies(df, columns=['type', \"distType\"])\n",
    "        df.drop(columns=[\"step\", \"nameOrig\", \"nameDest\", \"isFlaggedFraud\"], inplace=True)\n",
    "\n",
    "        \n",
    "        return df\n",
    "\n",
    "    \n",
    "columns = ['amount', 'oldbalanceOrg_imputed', 'newbalanceOrig', 'oldbalanceDest',\n",
    "   'newbalanceDest_imputed']\n",
    "\n",
    "preprocessor = Preprocess(scaler_columns=columns)\n",
    "\n",
    "preprocessor.fit(df_train_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = preprocessor.transform(df_train_)\n",
    "df_test = preprocessor.transform(df_test_)\n",
    "df_val = preprocessor.transform(df_val_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(model, x_test, y_test, title=''):\n",
    "    \"\"\" evaluetes performance of the model\"\"\"\n",
    "    y_pred = model.predict(x_test)\n",
    "    performance_metrics(y_pred, y_test, labels=[True, False], title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['isFraud'])\n",
    "y_train = df_train['isFraud']\n",
    "X_test = df_test.drop(columns=['isFraud'])\n",
    "y_test = df_test['isFraud']\n",
    "\n",
    "X_val = df_val.drop(columns=['isFraud'])\n",
    "y_val = df_val['isFraud']\n",
    "features = ['amount', 'external_dest', 'oldbalanceOrg_imputed', 'newbalanceOrig', 'oldbalanceDest',\n",
    "       'newbalanceDest_imputed', 'deviation_from_max_7_days',\n",
    "       'deviation_from_max_3_days', 'type_CASH_IN', 'type_CASH_OUT', 'type_DEBIT',\n",
    "       'type_PAYMENT', 'type_TRANSFER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%script true\n",
    "# hyper parameter tuning\n",
    "dtc_model=DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "parameters = {'max_leaf_nodes': range(3,9,1)}\n",
    "\n",
    "gs_clf = GridSearchCV(dtc_model, parameters, cv=5, scoring='matthews_corrcoef')\n",
    "\n",
    "gs_clf.fit(X_val[features], y_val)\n",
    "dtc_model=gs_clf.best_estimator_\n",
    "print(gs_clf.best_estimator_)\n",
    "print('grid search score, cv=5,', gs_clf.best_score_)\n",
    "dtc_model.fit(X_train[features],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(dtc_model, feature_names=dtc_model.feature_names_in_, filled=True, fontsize=4, class_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance(dtc_model, x_test=X_test[features], y_test=y_test, title='dtc performance test set')\n",
    "performance(dtc_model, x_test=X_train[features], y_test=y_train, title='dtc performance train set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cart_predicates(cart_model, input_df, negation=True):\n",
    "    \"\"\" Creates data frame with columns from decision tree features and thresholds feature<threshold\"\"\"\n",
    "    bool_filter         = cart_model.tree_.feature>=0\n",
    "    chosen_features_id  = cart_model.tree_.feature[bool_filter]\n",
    "    chosen_features     = cart_model.feature_names_in_[chosen_features_id]\n",
    "    thresholds          = cart_model.tree_.threshold[bool_filter]\n",
    "    features_thresholds = list(set(list(zip(chosen_features, thresholds))))\n",
    "    features_thresholds.sort()\n",
    "    df = pd.DataFrame()\n",
    "    for ft in features_thresholds:\n",
    "        df[str(ft).replace('(','{').replace(')','}').replace('\\'','')] = input_df[ft[0]]<=ft[1]\n",
    "        if negation:\n",
    "            df['NOT'+str(ft).replace('(','{').replace(')','}').replace('\\'','')] = input_df[ft[0]]>ft[1]\n",
    "        \n",
    "    df['isFraud'] = input_df['isFraud']\n",
    "    predicates = df.columns[:-1]\n",
    "    return df, predicates\n",
    "\n",
    "train_predicates_cart, predicates = create_cart_predicates(dtc_model, df_train)\n",
    "test_predicates_cart,a = create_cart_predicates(dtc_model, df_test)\n",
    "\n",
    "create_facts_and_examples(df_=train_predicates_cart, target='isFraud', \\\n",
    "                          predicates=predicates, output_dir='examples/fraud-cart')\n",
    "\n",
    "test_predicates_cart.to_parquet(path='examples/fraud-cart/df_test.parquet')\n",
    "\n",
    "## No Negation\n",
    "\n",
    "train_predicates_cart_no_negation, predicates = create_cart_predicates(dtc_model, df_train, negation=False)\n",
    "test_predicates_cart_no_negation,a = create_cart_predicates(dtc_model, df_test, negation=False)\n",
    "\n",
    "create_facts_and_examples(df_=train_predicates_cart_no_negation, target='isFraud', \\\n",
    "                          predicates=predicates, output_dir='examples/fraud-cart-no-negation')\n",
    "test_predicates_cart_no_negation.to_parquet(path='examples/fraud-cart-no-negation/df_test.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#short version\n",
    "df_1 = train_predicates_cart[train_predicates_cart['isFraud']==0]\n",
    "df_2 = train_predicates_cart[train_predicates_cart['isFraud']==1]\n",
    "fraud_background = pd.concat([df_1.iloc[0:100], df_2.iloc[0:100]], ignore_index=True)\n",
    "\n",
    "\n",
    "create_facts_and_examples(df_=fraud_background, target='isFraud', \\\n",
    "                          predicates=predicates, output_dir='examples/fraud-cart-short')\n",
    "\n",
    "test_predicates_cart.to_parquet(path='examples/fraud-cart-short/df_test.parquet')\n",
    "\n",
    "\n",
    "## No Negation\n",
    "\n",
    "df_1 = train_predicates_cart_no_negation[train_predicates_cart_no_negation['isFraud']==0]\n",
    "df_2 = train_predicates_cart_no_negation[train_predicates_cart_no_negation['isFraud']==1]\n",
    "fraud_background = pd.concat([df_1.iloc[0:100], df_2.iloc[0:100]], ignore_index=True)\n",
    "\n",
    "\n",
    "create_facts_and_examples(df_=fraud_background, target='isFraud', \\\n",
    "                          predicates=predicates, output_dir='examples/fraud-cart-short-no-negation')\n",
    "\n",
    "test_predicates_cart_no_negation.to_parquet(path='examples/fraud-cart-short-no-negation/df_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "df_1 = df_train[df_train['isFraud']==0]\n",
    "df_2 = df_train[df_train['isFraud']==1]\n",
    "fraud_background_100_100 = pd.concat([df_1.iloc[0:100], df_2.iloc[0:100]], ignore_index=True)\n",
    "dtc_model_100_100 = copy.copy(dtc_model)\n",
    "dtc_model_100_100.fit(fraud_background_100_100[features], fraud_background_100_100['isFraud'])\n",
    "performance(dtc_model_100_100, x_test=X_test[features], y_test=y_test, title='dtc_model_100_100 performance test set')\n",
    "performance(dtc_model, x_test=fraud_background_100_100[features], y_test=fraud_background_100_100['isFraud'], title='dtc_model performance train set 100/100')\n",
    "performance(dtc_model_100_100, x_test=fraud_background_100_100[features], y_test=fraud_background_100_100['isFraud'], title='dtc_model_100_100 performance train set 100/100')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#short version 10-1000\n",
    "df_1 = train_predicates_cart[train_predicates_cart['isFraud']==0]\n",
    "df_2 = train_predicates_cart[train_predicates_cart['isFraud']==1]\n",
    "fraud_background = pd.concat([df_1.iloc[0:1000], df_2.iloc[0:10]], ignore_index=True)\n",
    "create_facts_and_examples(df_=fraud_background, target='isFraud', \\\n",
    "                          predicates=predicates, output_dir='examples/fraud-cart-short-1000-10')\n",
    "\n",
    "test_predicates_cart.to_parquet(path='examples/fraud-cart-short-1000-10/df_test.parquet')\n",
    "\n",
    "## No Negation\n",
    "\n",
    "## No Negation\n",
    "\n",
    "df_1 = train_predicates_cart_no_negation[train_predicates_cart_no_negation['isFraud']==0]\n",
    "df_2 = train_predicates_cart_no_negation[train_predicates_cart_no_negation['isFraud']==1]\n",
    "fraud_background = pd.concat([df_1.iloc[0:1000], df_2.iloc[0:10]], ignore_index=True)\n",
    "\n",
    "create_facts_and_examples(df_=fraud_background, target='isFraud', \\\n",
    "                          predicates=predicates, output_dir='examples/fraud-cart-short-1000-10-no-negation')\n",
    "\n",
    "test_predicates_cart_no_negation.to_parquet(path='examples/fraud-cart-short-1000-10-no-negation/df_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_train[df_train['isFraud']==0]\n",
    "df_2 = df_train[df_train['isFraud']==1]\n",
    "fraud_background_1000_10 = pd.concat([df_1.iloc[0:1000], df_2.iloc[0:10]], ignore_index=True)\n",
    "dtc_model_1000_10 = copy.copy(dtc_model)\n",
    "dtc_model_1000_10.fit(fraud_background_1000_10[features], fraud_background_1000_10['isFraud'])\n",
    "\n",
    "performance(dtc_model_1000_10, x_test=X_test[features], y_test=y_test, title='dtc_model_1000_10 performance test set')\n",
    "performance(dtc_model, x_test=fraud_background_1000_10[features], y_test=fraud_background_1000_10['isFraud'], title='dtc_model performance train set 1000/10')\n",
    "performance(dtc_model_1000_10, x_test=fraud_background_100_100[features], y_test=fraud_background_100_100['isFraud'], title='dtc_model_1000_10 performance train set 100/100')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare background knowledge, positive, and negative examples for DILP based on symbolic regression rule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_symbolic_predicates(input_df):\n",
    "    \"\"\" Creates data frame with columns from decision tree features and thresholds feature<threshold\"\"\"\n",
    "    #  type = transfer, and\n",
    "    # • externalDest = True, and\n",
    "    # • amount - maxDest7 > -0.15\n",
    "    fraud_background=input_df.copy()\n",
    "    fraud_background['deviation_from_max_7_days'] = fraud_background['deviation_from_max_7_days']>-0.15\n",
    "\n",
    "    predicates=['external_dest', 'type_CASH_IN', 'type_CASH_OUT', 'type_DEBIT', 'type_PAYMENT',\n",
    "                                       'type_TRANSFER', 'deviation_from_max_7_days']\n",
    "\n",
    "    return fraud_background, predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_predicates_symb, predicates_symb = create_symbolic_predicates(df_train)\n",
    "test_predicates_symb, a = create_symbolic_predicates(df_test)\n",
    "\n",
    "create_facts_and_examples(df_=train_predicates_symb, target='isFraud', \n",
    "                          predicates=predicates_symb, output_dir='examples/fraud-symb-full')\n",
    "test_predicates_symb.to_parquet(path='examples/fraud-symb-full/df_test.parquet')\n",
    "\n",
    "\n",
    "df_1 = train_predicates_symb[train_predicates_symb['isFraud']==0]\n",
    "df_2 = train_predicates_symb[train_predicates_symb['isFraud']==1]\n",
    "fraud_background = pd.concat([df_1.iloc[0:100], df_2.iloc[0:100]], ignore_index=True)\n",
    "\n",
    "\n",
    "create_facts_and_examples(df_=fraud_background, target='isFraud', \n",
    "                          predicates=predicates_symb, output_dir='examples/fraud-symb-100-100')\n",
    "\n",
    "test_predicates_symb.to_parquet(path='examples/fraud-symb-100-100/df_test.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_predicates_symb, predicates_symb = create_symbolic_predicates(df_train)\n",
    "test_predicates_symb,a = create_symbolic_predicates(df_test)\n",
    "\n",
    "\n",
    "df_1 = train_predicates_symb[train_predicates_symb['isFraud']==0]\n",
    "df_2 = train_predicates_symb[train_predicates_symb['isFraud']==1]\n",
    "fraud_background = pd.concat([df_1.iloc[0:1000], df_2.iloc[0:10]], ignore_index=True)\n",
    "\n",
    "\n",
    "create_facts_and_examples(df_=fraud_background, target='isFraud', \n",
    "                          predicates=predicates_symb, output_dir='examples/fraud-symb-10-1000')\n",
    "\n",
    "test_predicates_symb.to_parquet(path='examples/fraud-symb-10-1000/df_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0, \"break before ripper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(test_predicates_symb['type_TRANSFER']&test_predicates_symb['type_CASH_OUT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RIPPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wittgenstein as lw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pypi.org/project/wittgenstein/\n",
    "#https://www.geeksforgeeks.org/ripper-algorithm/\n",
    "#https://github.com/imoscovitz/wittgenstein#useful-references\n",
    "ripper_clf = lw.RIPPER() # Or irep_clf = lw.IREP() to build a model using IREP\n",
    "ripper_clf.fit(X_train,y_train) # Or pass X and y data to .fit\n",
    "ripper_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper_clf.out_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance(ripper_clf, x_test=X_test, y_test=y_test)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1069,
     "sourceId": 1940,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
